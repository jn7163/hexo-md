---
title: (c语言)数据结构与算法 - 基本概念
date: 2017-07-23 16:35:00
categories:
- c
- 数据结构与算法
tags:
- c
- 数据结构与算法
keywords: c语言 数据结构与算法 基本概念
---

> 
在计算机科学中，`数据结构(data structure)`是计算机中`存储、组织数据的方式`；
数据结构可透过程序语言所提供的数据类型、引用及其他操作加以实现；
一个设计良好的数据结构，应该在尽可能使用较少的时间与空间资源的前提下，支持各种程序运行。
不同种类的数据结构适合不同种类的应用，部分数据结构甚至是为了解决特定问题而设计出来的；
例如B树即为加快树状结构访问速度而设计的数据结构，常被应用在数据库和文件系统上。
正确的数据结构选择可以提高算法的效率，在计算机程序设计的过程里，选择适当的数据结构是一项重要工作。

<!-- more -->

## 为什么要学习数据结构
数据结构是计算机科学与技术专业的专业基础课，是十分重要的核心课程。
所有的计算机系统软件和应用软件都要用到各种类型的数据结构。
因此，要想更好地运用计算机来解决实际问题，仅掌握几种计算机程序设计语言是难以应付众多复杂的课题的。
要想有效地使用计算机、充分发挥计算机的性能，还必须学习和掌握好数据结构的有关知识。
打好“数据结构”这门课程的扎实基础，对于学习计算机专业的其他课程都是十分有益的

## 三个层次、五个要素
数据结构的内容包括三个层次、五个要素，如下表：
<table><tr><th></th><th>数据表示</th><th>数据处理</th></tr><tr><td>抽象</td><td>逻辑结构</td><td>基本运算</td></tr><tr><td>实现</td><td>存储结构</td><td>算法</td></tr><tr><td>评价</td><td colspan="2">不同数据结构的比较及算法分析</td></tr></table>

## 相关概念及术语
**`数据`**
数据是信息的载体，是描述客观事物属性的数、字符以及所有能输入到计算机中并被计算机程序识别和处理的符号的集合

**`数据元素`**
数据元素指组成数据的、`有意义`的`基本单位`，也被称为记录

**`数据项`**
数据项是数据`不可分割`的`最小单位`，一个数据元素可以由若干数据项组成

**`数据对象`**
数据对象指`性质相同`的`数据元素`的`集合`，是数据的子集
`性质相同`指数据元素具有`相同数量`和`类型`的`数据项`

**`数据结构`**
数据结构指互相之间存在一种或多种`特定关系`的`数据元素的集合`
`数据结构 = 数据元素 + 关系`
数据结构包括数据的`逻辑结构`和数据的`物理结构(存储结构)`

**`逻辑结构`**
逻辑结构指数据对象中`数据元素之间`的`相互关系`
逻辑结构分为`集合结构`、`线性结构`、`树形结构`和`图形结构`
- `集合结构`
其中的数据元素除`同属于一个集合`外，之间没有其他关系
- `线性结构`
其中的数据元素之间是`一对一`的关系
- `树形结构`
其中的数据元素之间存在`一对多`的层次关系
- `图形结构`
其中的数据元素之间存在`多对多`的关系

**`存储结构`**
物理结构指数据的逻辑结构在`计算机内存`中的`存储形式`
存储结构分四类：`顺序存储`、`链接存储`、`索引存储`和`散列存储`
`顺序结构`和`链接结构`适用在`内存结构`中
`索引结构`和`散列结构`适用在`外存与内存交互`结构
- `顺序存储`
在计算机中用一组地址连续的存储单元依次存储线性表的各个数据元素，称作线性表的顺序存储结构
 - 特点：
 - 随机存取表中元素
 - 插入和删除操作需要移动元素

- `链接存储`
在计算机中用一组任意的存储单元存储线性表的数据元素(这组存储单元可以是连续的，也可以是不连续的)
它不要求逻辑上相邻的元素在物理位置上也相邻，因此它没有顺序存储结构所具有的弱点，但也同时失去了顺序表可随机存取的优点
 - 特点：
 - 比顺序存储结构的存储密度小(每个节点都由数据域和指针域组成，所以相同空间内假设全存满的话顺序比链式存储更多)
 - 逻辑上相邻的节点物理上不必相邻
 - 插入、删除灵活(不必移动节点，只要改变节点中的指针)
 - 查找结点时链式存储要比顺序存储慢
 - 每个结点是由数据域和指针域组成

- `索引存储`
除建立存储结点信息外，还建立附加的`索引表`来标识结点的地址。索引表由若干索引项组成
 - 特点：
 - 索引存储结构是用结点的索引号来确定结点存储地址，其优点是检索速度快，缺点是增加了附加的索引表，会占用较多的存储空间

- `散列存储`
散列存储，又称hash存储，是一种力图将数据元素的存储位置与关键码之间建立确定对应关系的查找技术
散列法存储的基本思想是：由节点的关键码值决定节点的存储地址。散列技术除了可以用于查找外，还可以用于存储
 - 特点：
 - 散列是数组存储方式的一种发展，相比数组，散列的数据访问速度要高于数组，因为可以依据存储数据的部分内容找到数据在数组中的存储位置，进而能够快速实现数据的访问，理想的散列访问速度是非常迅速的，而不像在数组中的遍历过程，采用存储数组中内容的部分元素作为映射函数的输入，映射函数的输出就是存储数据的位置，这样的访问速度就省去了遍历数组的实现，因此时间复杂度可以认为是O(1)，而数组遍历的时间复杂度为O(n)

**逻辑结构面向问题，物理结构面向计算机，其基本目标是将数据及其逻辑关系存储到计算机的内存中**

**`数据类型`**
在用高级语言编写的程序中，每个变量、常量或表达式都有一个它所属的确定的数据类型
类型显式地或隐含地规定了在程序执行期间变量或表达式所有`可能的取值范围`，以及在这些值上`允许进行的操作`
数据类型(Data Type)是一个`值的集合`和定义在这个值集上的`一组操作`的总称
在高级程序设计语言中，数据类型可分为两类：
一类是`原子类型`，另一类则是`结构类型`。原子类型的值是不可分解的

**`抽象数据类型`**
抽象数据类型(Abstruct Data Type，简称ADT)是指一个`数学模型`以及定义在该模型上的`一组操作`
抽象数据类型的定义取决于它的一组`逻辑特性`，而与其在计算机`内部如何表示和实现无关`
即不论其内部结构如何变化，只要它的数学特性不变，都不影响其外部的使用
`抽象数据类型`和`数据类型`实质上是一个概念，`数据类型`的重点在`具体的实现`，`抽象数据类型`则只关心它的`逻辑特性`

例如，各种计算机都拥有的"整数类型"就是一个抽象数据类型，尽管它们在不同处理器上的实现方法可以不同，但由于其定义的数学特性相同，在用户看来都是相同的。因此，“抽象”的意义在于数据类型的数学抽象特性

为了提高软件的重用性，在近代程序设计方法学中，要求在构成软件系统的每个相对独立的模块上，定义一组数据和施于这些数据上的一组操作，并在模块的内部给出这些数据的表示及其操作的细节，而在模块的外部使用的只是抽象的数据及抽象的操作。这也就是`面向对象`的程序设计方法

`抽象数据类型`的定义可以由`一种数据结构`和定义在其上的`一组操作`组成;
而`数据结构`又包括`数据元素`及`元素间的关系`;
因此`抽象数据类型`一般可以由`元素`、`关系`及`操作`三种要素来定义

抽象数据类型的特征是使用与实现相分离，实行封装和信息隐蔽。就是说，在抽象数据类型设计时，把类型的定义与其实现分离开来

## 算法与算法分析
`算法`与`数据结构`的关系紧密，在算法设计时先要确定相应的数据结构，而在讨论某一种数据结构时也必然会涉及相应的算法

**算法特性**
算法(Algorithm)是对特定问题`求解步骤的一种描述`，是`指令的有限序列`，其中每一条指令表示一个或多个操作。一个算法应该具有下列特性：
- `有穷性`：一个算法必须在有穷步之后结束，即必须在有限时间内完成;
- `确定性`：算法的每一步必须有确切的定义，无二义性。算法的执行对应着的相同的输入仅有唯一的一条路经;
- `可行性`：算法中的每一步都可以通过已经实现的基本运算的有限次执行得以实现;
- `输入`：一个算法具有零个或多个输入，这些输入取自特定的数据对象集合;
- `输出`：一个算法具有一个或多个输出，这些输出同输入之间存在某种特定的关系。

**算法与数据结构是相辅相承的**
解决某一特定类型问题的算法可以选定不同的数据结构，而且选择恰当与否直接影响算法的效率；
反之，一种数据结构的优劣由各种算法的执行来体现，要设计一个好的算法通常要考虑以下的要求：
- `正确`：算法的执行结果应当满足预先规定的功能和性能要求；
- `可读`：一个算法应当思路清晰、层次分明、简单明了、易读易懂；
- `健壮`：当输入不合法数据时，应能作适当处理，不至引起严重后果；
- `高效`：有效使用存储空间和有较高的时间效率。

**算法的描述**
算法描述是指对设计出的算法，用一种方式进行详细的描述，以便与人交流。
描述可以使用`自然语言`、`伪代码`，也可使用`程序流程图`，但描述的结果必须满足算法的五个特征。

使用自然语言描述算法显然很有吸引力，但是自然语言固有的不严密性使得要简单清晰的描述算法变得很困难。因此，使用伪代码来描述算法是一个很好的选择。

`伪代码`是自然语言和类编程语言组成的混合结构。它比自然语言更精确，描述算法很简洁；同时也可以很容易转换成计算机程序。
虽然如此，但计算机科学家们从来就没有对伪代码的形式达成共识，不同作者的教材会设计他们自己的“方言”（伪代码）。
幸运的是，这些伪代码都十分相似，任何熟悉一门现代变成语言的人都完全能够理解。

使用伪代码描述算法可以让程序员很容易将算法转换成程序，同时还可以避开不同程序语言的语法差别

**算法性能分析与度量**
我们可以从一个算法的`时间复杂度`与`空间复杂度`来评价算法的优劣

当我们将一个算法转换成程序并在计算机上执行时，其运行所需要的时间取决于下列因素：
- `硬件的速度`：例如使用486机还是使用586机;
- `书写程序的语言`：实现语言的级别越高，其执行效率就越低;
- `目标代码的质量`：对于代码优化较好的编译程序其所生成的程序质量较高;
- `问题的规模`：例如，求100 以内的素数与求1000 以内的素数其执行时间必然是不同的。

显然，在各种因素都不能确定的情况下，很难比较出算法的执行时间。
也就是说，使用执行算法的绝对时间来衡量算法的效率是不合适的。
为此，可以将上述各种与计算机`相关的软、硬件因素都确定下来`，这样一个特定算法的运行工作量的大小就只依赖于`问题的规模`(通常用正整数n表示)，或者说它是`问题规模的函数`

通常，对于一个给定的算法，我们要做两项分析：
第一是从`数学上证明算法的正确性`，这一步主要用到形式化证明的方法及相关推理模式，如循环不变式、数学归纳法等;
而在证明算法是正确的基础上，第二步就是`分析算法的时间复杂度`；算法的时间复杂度反映了程序执行时间随输入规模增长而增长的量级，在很大程度上能很好反映出算法的优劣与否
因此，作为程序员，掌握基本的算法时间复杂度分析方法是很有必要的

算法执行时间需通过依据该算法编制的程序在计算机上运行时所消耗的时间来度量。而度量一个程序的执行时间通常有两种方法：
**`事后统计的方法`**
这种方法可行，但不是一个好的方法。该方法有两个缺陷：
一是要想对设计的算法的运行性能进行评测，必须先依据算法编制相应的程序并实际运行；
二是所得时间的统计量依赖于计算机的硬件、软件等环境因素，有时容易掩盖算法本身的优势。

**`事前分析估算的方法`**
因事后统计方法更多的依赖于计算机的硬件、软件等环境因素，有时容易掩盖算法本身的优劣。因此人们常常采用事前分析估算的方法。
在编写程序前，依据统计方法对算法进行估算。一个用高级语言编写的程序在计算机上运行时所消耗的时间取决于下列因素：
(1)算法采用的策略、方法；(2)编译产生的代码质量；(3)问题的输入规模；(4)机器执行指令的速度

一个算法是由`控制结构(顺序、分支和循环3种)`和`原操作(指固有数据类型的操作)`构成的，则算法时间取决于两者的综合效果。
为了便于比较同一个问题的不同算法，通常的做法是：从算法中选取一种对于所研究的问题(或算法类型)来说是`基本操作的原操作`，以该基本操作的`重复执行的次数`作为算法的`时间量度`

**`时间频度`**
一个算法执行所耗费的时间，从理论上是不能算出来的，必须上机运行测试才能知道。
但我们不可能也没有必要对每个算法都上机测试，只需知道哪个算法花费的时间多，哪个算法花费的时间少就可以了。
并且一个算法花费的时间与算法中语句的执行次数成正比例，哪个算法中语句执行次数多，它花费时间就多。
一个算法中的`语句执行次数`称为`语句频度`或`时间频度`，记为`T(n)`

**`时间复杂度`**
在刚才提到的时间频度中，`n`称为`问题的规模`，当n不断变化时，时间频度`T(n)`也会不断变化。
但有时我们想知道它变化时呈现什么规律，为此，我们引入`时间复杂度`概念。
一般情况下，算法中`基本操作重复执行的次数`是`问题规模n`的某个`函数`，用`T(n)`表示;
若有某个`辅助函数f(n)`,使得当`n趋近于无穷大`时，`T(n)/f(n)`的极限值为`不等于零的常数`;
则称`f(n)是T(n)的同数量级函数`，记作`T(n)=Ｏ(f(n))`,称`Ｏ(f(n))`为算法的`渐进时间复杂度`，简称`时间复杂度`

`T(n)=Ο(f(n))`表示存在一个`常数C`，使得在当`n趋于正无穷`时总有`T(n)≤C*f(n)`
简单来说，就是`T(n)`在`n趋于正无穷`时最大也就跟`f(n)差不多大`，也就是说当n趋于正无穷时`T(n)`的上界是`C*f(n)`
其虽然对`f(n)`没有规定，但是一般都是`取尽可能简单的函数`。
例如，`O(2n^2+n+1) = O(3n^2+n+3) = O(7n^2+n) = O(n^2)`，一般都只用`O(n^2)`表示就可以了
注意到大O符号里隐藏着一个常数C，所以f(n)里一般不加系数，如果把T(n)当做一棵树，那么O(f(n))所表达的就是树干，只关心其中的主干，其他的细枝末节全都抛弃不管

在各种不同算法中，若算法中`语句执行次数为一个常数`，则时间复杂度为`O(1)`

另外，在时间频度不相同时，时间复杂度有可能相同，如`T(n)=n^2+3n+4`与`T(n)=4n^2+2n+1`它们的频度不同，但时间复杂度相同，都为`O(n^2)`

按数量级递增排列，常见的时间复杂度有：
`常数阶O(1)`、`对数阶O(log2n)`、`线性阶O(n)`、`线性对数阶O(nlog2n)`、`平方阶O(n^2`)、`立方阶O(n^3)`、`k次方阶O(n^k)`、`指数阶O(2^n)`
随着问题规模n的不断增大，上述时间复杂度不断增大，算法的执行效率越低

常见的算法时间复杂度`由小到大`依次为：`Ο(1) < Ο(log2n) < Ο(n) < Ο(nlog2n) < Ο(n^2) < Ο(n^3) < Ο(2^n) < Ο(n!)`
可见，我们应该尽可能选用`多项式阶O(n^k)`的算法，而不希望用`指数阶`的算法

一般情况下，对一个问题(或一类算法)只需选择一种基本操作来讨论算法的时间复杂度即可;
有时也需要同时考虑几种基本操作，甚至可以对不同的操作赋予不同的权值，以反映执行不同操作所需的相对时间，这种做法便于综合比较解决同一问题的两种完全不同的算法

**求解算法的`时间复杂度`的具体步骤**
- 找出算法中的基本语句：
算法中`执行次数最多`的那条语句就是`基本语句`，通常是`最内层循环的循环体`
- 计算基本语句的执行次数的数量级：
只需计算基本语句执行次数的数量级，这就意味着只要保证基本语句执行次数的函数中的最高次幂正确即可，可以忽略所有低次幂和最高次幂的系数。这样能够简化算法分析，并且使注意力集中在最重要的一点上：增长率
- 用大Ο记号表示算法的时间性能：
将基本语句执行次数的数量级放入大Ο记号中
如果算法中包含`嵌套的循环`，则基本语句通常是`最内层的循环体`;
如果算法中包含`并列的循环`，则将并列循环的`时间复杂度相加`

**求时间复杂度简单例子**
<pre><code class="language-c line-numbers"><script type="text/plain">for(int i=0; i<n; i++){
    x++;
}
for(int i=0; i<n; i++){
    for(int j=0; j<n; j++){
        x--;
    }
}
</script></code></pre>

第一个for循环的时间复杂度为`O(n)`; 第二个for循环的时间复杂度为`O(n^2)`; 所以整个算法的时间复杂度为`O(n+n^2) = O(n^2)`

**求时间复杂度简单分析**
`Ο(1)`表示`基本语句的执行次数`是一个`常数`，一般来说，只要算法中不存在循环语句，其时间复杂度就是`Ο(1)`
其中`Ο(log2n)`、`Ο(n)`、`Ο(nlog2n)`、`Ο(n^2)`和`Ο(n^3)`称为`多项式时间`; 而`Ο(2^n)`和`Ο(n!)`称为`指数时间`
计算机科学家普遍认为前者(即`多项式时间复杂度的算法`)是`有效算法`，把这类问题称为`P(Polynomial,多项式)类问题`;
而把后者(即`指数时间复杂度的算法`)称为`NP(Non-Deterministic Polynomial,非确定多项式)问题`。

几个简单的分析法则:
- 对于一些简单的`输入输出`语句或`赋值`语句，近似认为需要`O(1)`时间
- 对于`顺序结构`，需要依次执行一系列语句所用的时间可采用大O下`求和法则`
求和法则是指若算法的2个部分时间复杂度分别为`T1(n)=O(f(n))`和`T2(n)=O(g(n))`，则`T1(n)+T2(n)=O(max(f(n), g(n)))`
特别地，若`T1(m)=O(f(m))`，`T2(n)=O(g(n))`，则`T1(m)+T2(n)=O(f(m) + g(n))`
- 对于`选择结构`，如if语句，它的主要时间耗费是在执行then字句或else字句所用的时间，需注意的是检验条件也需要`O(1)`时间
- 对于`循环结构`，循环语句的运行时间主要体现在多次迭代中执行循环体以及检验循环条件的时间耗费，一般可用大O下`乘法法则`
乘法法则是指若算法的2个部分时间复杂度分别为`T1(n)=O(f(n))`和`T2(n)=O(g(n))`，则`T1*T2=O(f(n)*g(n))`
- 对于`复杂的算法`，可以将它分成几个容易估算的部分，然后利用`求和法则`和`乘法法则`计算整个算法的时间复杂度
- 另外还有以下2个运算法则:
(1) 若`g(n)=O(f(n))`，则`O(f(n))+O(g(n))=O(f(n))`；
(2) `O(Cf(n))=O(f(n))`，其中C是一个正常数


**`空间复杂度`**
类似于时间复杂度的讨论，一个算法的`空间复杂度(Space Complexity)` - `S(n)`
定义为该算法所`耗费的存储空间`，它也是`问题规模n的函数`，渐近空间复杂度也常常简称为空间复杂度

空间复杂度是对一个算法在运行过程中临时占用存储空间大小的量度。

一个算法在计算机存储器上所占用的存储空间，包括存储`算法本身所占用的存储空间`、算法的`输入输出数据所占用的存储空间`和算法在运行过程中`临时占用的存储空间`这三个方面：
- 算法的`输入输出数据所占用的存储空间`是由要解决的问题决定的，是通过参数表由调用函数传递而来的，它`不随本算法的不同而改变`
- 存储`算法本身所占用的存储空间`与算法`书写的长短`成`正比`，要压缩这方面的存储空间，就必须编写出较短的算法
- 算法在运行过程中`临时占用的存储空间`随算法的不同而异，有的算法只需要占用少量的临时工作单元，而且不随问题规模的大小而改变，我们称这种算法是`就地进行`的，是节省存储的算法；有的算法需要占用的临时工作单元数与解决问题的规模n有关，它随着n的增大而增大，当n较大时，将占用较多的存储单元

当一个算法的空间复杂度为一个`常量`，即不随被处理数据量n的大小而改变时，可表示为`O(1)`;
当一个算法的空间复杂度与`以2为底的n的对数`成正比时，可表示为`O(log2n)`;
当一个算法的空间复杂度`与n成线性比例关系`时，可表示为`O(n)`
